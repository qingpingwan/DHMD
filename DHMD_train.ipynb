{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP模型的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "devices = \"cuda:0\"\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"/data4/zxf/hf/openai/clip-vit-large-patch14\").to(devices)\n",
    "processor = CLIPProcessor.from_pretrained(\"/data4/zxf/hf/openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VisualProjection(nn.Module):\n",
    "    def __init__(self, visual_projection):\n",
    "        super().__init__()\n",
    "        self.visual_projection = visual_projection\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        将输入张量 x 映射到 (batch, len, 768)\n",
    "        \"\"\"\n",
    "        x = self.visual_projection(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TextProjection(nn.Module):\n",
    "    def __init__(self, visual_projection):\n",
    "        super().__init__()\n",
    "        self.visual_projection = visual_projection\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        将输入张量 x 映射到 (batch, len, 768)\n",
    "        \"\"\"\n",
    "        x = self.visual_projection(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "visual_projection = clip_model.visual_projection\n",
    "Text_projection = clip_model.text_projection\n",
    "\n",
    "\n",
    "# 创建 VisualProjection 模块并进行测试\n",
    "Visual_module = VisualProjection(visual_projection).to(devices)\n",
    "# input_tensor_1 = outputs[\"vision_model_output\"][\"last_hidden_state\"]\n",
    "# Visual_output_tensor = Visual_module(input_tensor_1)\n",
    "\n",
    "\n",
    "\n",
    "Text_module = TextProjection(Text_projection).to(devices)\n",
    "# input_tensor_2 = outputs[\"text_model_output\"][\"last_hidden_state\"]\n",
    "# Text_output_tensor = Text_module(input_tensor_2)\n",
    "\n",
    "# print(Text_output_tensor.size())\n",
    "# print(Visual_output_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLIP_pipeline(x1,x2):\n",
    "    tmp_inputs_text = processor(text=x1, return_tensors=\"pt\", padding=True,truncation=True, max_length=77).to(devices)\n",
    "    tmp_inputs_image = processor(images=x2, return_tensors=\"pt\").to(devices)\n",
    "    \n",
    "    outputs_1 = clip_model.text_model(**tmp_inputs_text)\n",
    "    outputs_2 = clip_model.vision_model(**tmp_inputs_image)\n",
    "    outputs_tensor_1 = outputs_1[\"last_hidden_state\"]\n",
    "    Text_output_tensor = Text_module(outputs_tensor_1)\n",
    "    outputs_tensor_2 = outputs_2[\"last_hidden_state\"]\n",
    "    Visual_output_tensor = Visual_module(outputs_tensor_2)\n",
    "    return Text_output_tensor,Visual_output_tensor\n",
    "\n",
    "# x1 = [\"a photo of a cat\", \"a photo of a dog\"]\n",
    "# x2 = [Image.open(requests.get(\"http://images.cocodataset.org/val2017/000000039769.jpg\", stream=True).raw),\n",
    "#       Image.open(requests.get(\"http://images.cocodataset.org/val2017/000000397133.jpg\", stream=True).raw)]\n",
    "\n",
    "# x1,x2 = CLIP_pipeline(x1,x2)\n",
    "\n",
    "# print(x1.size())\n",
    "# print(x2.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络层的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class multimodal_attention(nn.Module):\n",
    "    \"\"\"\n",
    "    dot-product attention mechanism\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, attention_dropout=0.5):\n",
    "        super(multimodal_attention, self).__init__()\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, scale=None, attn_mask=None):\n",
    "\n",
    "        attention = torch.matmul(q, k.transpose(-2, -1))\n",
    "        # print('attention.shape:{}'.format(attention.shape))\n",
    "        if scale:\n",
    "            attention = attention * scale\n",
    "\n",
    "        if attn_mask:\n",
    "            attention = attention.masked_fill_(attn_mask, -np.inf)\n",
    "            \n",
    "        attention = self.softmax(attention)\n",
    "        # print('attention.shftmax:{}'.format(attention))\n",
    "        attention = self.dropout(attention)\n",
    "        v_result = torch.matmul(attention, v)\n",
    "        # print('attn_final.shape:{}'.format(attention.shape))\n",
    "\n",
    "        return v_result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Cross Attention mechanism\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_dim=768, num_heads=8, dropout=0.5):\n",
    "        super(CrossAttention, self).__init__()\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.dim_per_head = model_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.linear_q = nn.Linear(model_dim, self.dim_per_head * num_heads, bias=False)\n",
    "        self.linear_k = nn.Linear(model_dim, self.dim_per_head * num_heads, bias=False)\n",
    "        self.linear_v = nn.Linear(model_dim, self.dim_per_head * num_heads, bias=False)\n",
    "\n",
    "        self.dot_product_attention = multimodal_attention(dropout)\n",
    "        self.linear_final = nn.Linear(model_dim, model_dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(model_dim)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None):\n",
    "        residual = query\n",
    "\n",
    "        # Linear projection\n",
    "        query = self.linear_q(query)\n",
    "        key = self.linear_k(key)\n",
    "        value = self.linear_v(value)\n",
    "\n",
    "        # Split by heads\n",
    "        batch_size = query.size(0)\n",
    "        query = query.view(batch_size, -1, self.num_heads, self.dim_per_head).transpose(1, 2)\n",
    "        key = key.view(batch_size, -1, self.num_heads, self.dim_per_head).transpose(1, 2)\n",
    "        value = value.view(batch_size, -1, self.num_heads, self.dim_per_head).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot product attention\n",
    "        scale = (self.dim_per_head) ** -0.5\n",
    "        attention = self.dot_product_attention(query, key, value, scale, attn_mask)\n",
    "\n",
    "        # Concatenate heads\n",
    "        attention = attention.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.dim_per_head)\n",
    "\n",
    "        # Final linear projection\n",
    "        output = self.linear_final(attention)\n",
    "\n",
    "        # Dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # Add residual and norm layer\n",
    "        output = self.layer_norm(residual + output)\n",
    "\n",
    "        return output\n",
    "\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, model_dim=768, num_heads=8, dropout=0.5):\n",
    "        super(MultiHeadCrossAttention, self).__init__()\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.dim_per_head = model_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.cross_attention = CrossAttention(model_dim, num_heads, dropout)\n",
    "        self.layer_norm = nn.LayerNorm(model_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x1, x2, attn_mask=None):\n",
    "        # Cross attention from x1 to x2\n",
    "        cross_attn_output_1 = self.cross_attention(x1, x2, x2, attn_mask)\n",
    "        # Cross attention from x2 to x1\n",
    "        cross_attn_output_2 = self.cross_attention(x2, x1, x1, attn_mask)\n",
    "\n",
    "        # Combine the outputs\n",
    "        output_1 = self.layer_norm(x1 + cross_attn_output_1)\n",
    "        output_2 = self.layer_norm(x2 + cross_attn_output_2)\n",
    "\n",
    "        return output_1, output_2\n",
    "\n",
    "# # Example usage\n",
    "# batch_1, len_1, dim = 2, 10, 768\n",
    "# batch_2, len_2, dim = 2, 15, 768\n",
    "\n",
    "# x1 = torch.randn(batch_1, len_1, dim)\n",
    "# x2 = torch.randn(batch_2, len_2, dim)\n",
    "\n",
    "# layer = MultiHeadCrossAttention(model_dim=768, num_heads=8, dropout=0.5)\n",
    "# output_1, output_2 = layer(x1, x2)\n",
    "\n",
    "\n",
    "# print(\"output_1 shape:\", output_1.size())  # Expected: [batch_1, len_1, 768]\n",
    "# print(\"output_2 shape:\", output_2.size())  # Expected: [batch_2, len_2, 768]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Self Attention mechanism\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_dim=768, num_heads=8, dropout=0.5):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.dim_per_head = model_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.linear_q = nn.Linear(model_dim, self.dim_per_head * num_heads, bias=False)\n",
    "        self.linear_k = nn.Linear(model_dim, self.dim_per_head * num_heads, bias=False)\n",
    "        self.linear_v = nn.Linear(model_dim, self.dim_per_head * num_heads, bias=False)\n",
    "\n",
    "        self.dot_product_attention = multimodal_attention(dropout)\n",
    "        self.linear_final = nn.Linear(model_dim, model_dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(model_dim)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        residual = x\n",
    "\n",
    "        # Linear projection\n",
    "        query = self.linear_q(x)\n",
    "        key = self.linear_k(x)\n",
    "        value = self.linear_v(x)\n",
    "\n",
    "        # Split by heads\n",
    "        batch_size = query.size(0)\n",
    "        query = query.view(batch_size, -1, self.num_heads, self.dim_per_head).transpose(1, 2)\n",
    "        key = key.view(batch_size, -1, self.num_heads, self.dim_per_head).transpose(1, 2)\n",
    "        value = value.view(batch_size, -1, self.num_heads, self.dim_per_head).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot product attention\n",
    "        scale = (self.dim_per_head) ** -0.5\n",
    "        attention = self.dot_product_attention(query, key, value, scale, attn_mask)\n",
    "\n",
    "        # Concatenate heads\n",
    "        attention = attention.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.dim_per_head)\n",
    "\n",
    "        # Final linear projection\n",
    "        output = self.linear_final(attention)\n",
    "\n",
    "        # Dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # Add residual and norm layer\n",
    "        output = self.layer_norm(residual + output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# # Example usage\n",
    "# batch_size = 2\n",
    "# seq_len = 10\n",
    "# model_dim = 768\n",
    "\n",
    "# x = torch.randn(batch_size, seq_len, model_dim)\n",
    "\n",
    "# self_attention = MultiHeadSelfAttention(model_dim=model_dim, num_heads=8, dropout=0.5)\n",
    "# output = self_attention(x)\n",
    "\n",
    "# print(\"output shape:\", output.size())  # Expected: [batch_size, seq_len, model_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, model_dim=768, num_heads=8, dropout=0.5):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_per_head = model_dim // num_heads\n",
    "        \n",
    "        self.linear_q = nn.Linear(model_dim, model_dim)\n",
    "        self.linear_k = nn.Linear(model_dim, model_dim)\n",
    "        self.linear_v = nn.Linear(model_dim, model_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.linear_out = nn.Linear(model_dim, model_dim)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        query = self.linear_q(query).view(batch_size, -1, self.num_heads, self.dim_per_head).transpose(1, 2)\n",
    "        key = self.linear_k(key).view(batch_size, -1, self.num_heads, self.dim_per_head).transpose(1, 2)\n",
    "        value = self.linear_v(value).view(batch_size, -1, self.num_heads, self.dim_per_head).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / (self.dim_per_head ** 0.5)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attn = self.softmax(scores)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        context = torch.matmul(attn, value).transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.dim_per_head)\n",
    "        output = self.linear_out(context)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class CoAttention(nn.Module):\n",
    "    def __init__(self, model_dim=768, num_heads=8, dropout=0.5):\n",
    "        super(CoAttention, self).__init__()\n",
    "        self.attention1 = MultiHeadAttention(model_dim, num_heads, dropout)\n",
    "        self.attention2 = MultiHeadAttention(model_dim, num_heads, dropout)\n",
    "        self.linear_out = nn.Linear(2 * model_dim, model_dim)\n",
    "        self.layer_norm = nn.LayerNorm(model_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x1, x2, mask1=None, mask2=None):\n",
    "        attn_output1 = self.attention1(x1, x2, x2, mask2)\n",
    "        attn_output2 = self.attention2(x2, x1, x1, mask1)\n",
    "        \n",
    "        combined = torch.cat([attn_output1.mean(dim=1), attn_output2.mean(dim=1)], dim=-1)\n",
    "        output = self.dropout(self.linear_out(combined))\n",
    "        output = self.layer_norm(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "# class CoAttention(nn.Module):\n",
    "#     def __init__(self, model_dim=768, num_heads=8, dropout=0.5):\n",
    "#         super(CoAttention, self).__init__()\n",
    "#         self.attention1 = MultiHeadAttention(model_dim, num_heads, dropout)\n",
    "#         self.attention2 = MultiHeadAttention(model_dim, num_heads, dropout)\n",
    "#         self.linear_out = nn.Linear(2 * model_dim, model_dim)\n",
    "#         self.layer_norm1 = nn.LayerNorm(model_dim)\n",
    "#         self.layer_norm2 = nn.LayerNorm(model_dim)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "#     def forward(self, x1, x2, mask1=None, mask2=None):\n",
    "#         attn_output1 = self.layer_norm1(x1 + self.attention1(x1, x2, x2, mask2))\n",
    "#         attn_output2 = self.layer_norm2(x2 + self.attention2(x2, x1, x1, mask1))\n",
    "#         # print(attn_output1.size())\n",
    "#         # print(attn_output2.size())\n",
    "        \n",
    "        \n",
    "#         # 使用更复杂的pooling策略,比如max pooling或者learned pooling\n",
    "#         pooled1 = attn_output1.max(dim=1)[0]\n",
    "#         pooled2 = attn_output2.max(dim=1)[0]\n",
    "        \n",
    "#         # print(pooled1.size())\n",
    "#         # print(pooled2.size())\n",
    "        \n",
    "#         combined = torch.cat([pooled1, pooled2], dim=-1)\n",
    "#         output = self.dropout(self.linear_out(combined))\n",
    "        \n",
    "#         return output\n",
    "\n",
    "\n",
    "# Example usage\n",
    "batch_size, len_1, len_2, dim = 2, 10, 15, 768\n",
    "\n",
    "x1 = torch.randn(batch_size, len_1, dim)\n",
    "x2 = torch.randn(batch_size, len_2, dim)\n",
    "\n",
    "model = CoAttention(model_dim=dim, num_heads=8, dropout=0.5)\n",
    "output = model(x1, x2)\n",
    "\n",
    "print(\"output shape:\", output.size())  # Expected: [batch, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_size=256, dropout=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(hidden_size, out_features)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "class VLR(nn.Module):\n",
    "    def __init__(self, dim=768):\n",
    "        super(VLR, self).__init__()\n",
    "        self.cross_layer_1 = MultiHeadCrossAttention(model_dim=dim, num_heads=16, dropout=0.5)\n",
    "        self.co_layer_1 = CoAttention(model_dim=dim, num_heads=16, dropout=0.5)\n",
    "        \n",
    "        \n",
    "        # self.layer_norm_1 = nn.LayerNorm(model_dim)\n",
    "        \n",
    "        # self.self_attention_1 = MultiHeadSelfAttention(model_dim=dim, num_heads=8, dropout=0.5)\n",
    "        # self.self_attention_2 = MultiHeadSelfAttention(model_dim=dim, num_heads=8, dropout=0.5)\n",
    "        \n",
    "        \n",
    "        self.mlp = MLP(in_features=dim, out_features=2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1, x2 = self.cross_layer_1(x1, x2)\n",
    "        # x1 = self.self_attention_1(x1)\n",
    "        # x2 = self.self_attention_2(x2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        output = self.co_layer_1(x1, x2)\n",
    "        output = self.mlp(output)\n",
    "        output = F.softmax(output, dim=-1)\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "import json\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, test_loader, criterion, optimizer, device):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        for x1, x2, labels in self.train_loader:\n",
    "\n",
    "            x1, x2 = CLIP_pipeline(x1,x2)\n",
    "            x1, x2, labels = x1.to(self.device), x2.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(x1, x2)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            running_loss += loss.item() * x1.size(0)\n",
    "        epoch_loss = running_loss / len(self.train_loader.dataset)\n",
    "        return epoch_loss\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x1, x2, labels in self.test_loader:\n",
    "                x1, x2 = CLIP_pipeline(x1,x2)\n",
    "                x1, x2, labels = x1.to(self.device), x2.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(x1, x2)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                running_loss += loss.item() * x1.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        epoch_loss = running_loss / len(self.test_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        return epoch_loss, accuracy\n",
    "    \n",
    "\n",
    "\n",
    "    def test_with_least_confidence(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        uncertainty_results = []  # To store uncertainty results\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x1, x2, labels in self.test_loader:\n",
    "                x1, x2 = CLIP_pipeline(x1, x2)\n",
    "                x1, x2, labels = x1.to(self.device), x2.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(x1, x2)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                running_loss += loss.item() * x1.size(0)\n",
    "                \n",
    "                # Least Confidence\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                max_probs, _ = torch.max(probs, dim=1)\n",
    "                uncertainties = 1 - max_probs  # Least confidence\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Collect results for each sample\n",
    "                for i in range(len(labels)):\n",
    "                    uncertainty_results.append({\n",
    "                        'true_label': labels[i].item(),\n",
    "                        'predicted_label': predicted[i].item(),\n",
    "                        'uncertainty': uncertainties[i].item()\n",
    "                    })\n",
    "\n",
    "        epoch_loss = running_loss / len(self.test_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        # Save results to JSON file\n",
    "        with open('least_confidence_results.json', 'w') as f:\n",
    "            json.dump(uncertainty_results, f, indent=4)\n",
    "\n",
    "        return epoch_loss, accuracy   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def test_with_prediction_entropy(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        uncertainty_results = []  # To store uncertainty results\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x1, x2, labels in self.test_loader:\n",
    "                x1, x2 = CLIP_pipeline(x1, x2)\n",
    "                x1, x2, labels = x1.to(self.device), x2.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(x1, x2)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                running_loss += loss.item() * x1.size(0)\n",
    "                \n",
    "                # Prediction Entropy\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1)  # Avoid log(0)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Collect results for each sample\n",
    "                for i in range(len(labels)):\n",
    "                    uncertainty_results.append({\n",
    "                        'true_label': labels[i].item(),\n",
    "                        'predicted_label': predicted[i].item(),\n",
    "                        'uncertainty': entropy[i].item()\n",
    "                    })\n",
    "\n",
    "        epoch_loss = running_loss / len(self.test_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        # Save results to JSON file\n",
    "        with open('prediction_entropy_results.json', 'w') as f:\n",
    "            json.dump(uncertainty_results, f, indent=4)\n",
    "\n",
    "        return epoch_loss, accuracy\n",
    "\n",
    "        \n",
    "    def test_with_monte_carlo_dropout(self, T=8):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        uncertainty_results = []  # To store uncertainty results\n",
    "        \n",
    "        # Enable dropout during inference (Monte Carlo Dropout)\n",
    "        def apply_dropout(model):\n",
    "            for module in model.modules():\n",
    "                if isinstance(module, torch.nn.Dropout):\n",
    "                    module.train()\n",
    "            return model\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x1, x2, labels in self.test_loader:\n",
    "                x1, x2 = CLIP_pipeline(x1, x2)\n",
    "                x1, x2, labels = x1.to(self.device), x2.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                # Apply dropout during inference\n",
    "                self.model = apply_dropout(self.model)\n",
    "                \n",
    "                all_outputs = []\n",
    "                for t in range(T):\n",
    "                    outputs = self.model(x1, x2)\n",
    "                    all_outputs.append(outputs.unsqueeze(0))\n",
    "                \n",
    "                # Stack and average the outputs for Monte Carlo estimation\n",
    "                all_outputs = torch.cat(all_outputs, dim=0)\n",
    "                mean_outputs = all_outputs.mean(dim=0)\n",
    "                \n",
    "                # Monte Carlo Dropout - using entropy as uncertainty measure\n",
    "                probs = F.softmax(mean_outputs, dim=1)\n",
    "                entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1)\n",
    "                \n",
    "                # Final prediction\n",
    "                _, predicted = torch.max(mean_outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Collect results for each sample\n",
    "                for i in range(len(labels)):\n",
    "                    uncertainty_results.append({\n",
    "                        'true_label': labels[i].item(),\n",
    "                        'predicted_label': predicted[i].item(),\n",
    "                        'uncertainty': entropy[i].item()\n",
    "                    })\n",
    "\n",
    "        epoch_loss = running_loss / len(self.test_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        # Save results to JSON file\n",
    "        with open('monte_carlo_dropout_results.json', 'w') as f:\n",
    "            json.dump(uncertainty_results, f, indent=4)\n",
    "\n",
    "        return epoch_loss, accuracy\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fit_uncertainty(self, epochs, uncertainty_method=\"LC\", T=8):\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Train for one epoch\n",
    "            train_loss = self.train_epoch()\n",
    "            \n",
    "            # Evaluate validation loss, accuracy, and uncertainty\n",
    "            if uncertainty_method == \"LC\":\n",
    "                val_loss, val_accuracy = self.test_with_least_confidence()\n",
    "            elif uncertainty_method == \"PE\":\n",
    "                val_loss, val_accuracy = self.test_with_prediction_entropy()\n",
    "            elif uncertainty_method == \"MCD\":\n",
    "                val_loss, val_accuracy = self.test_with_monte_carlo_dropout(T=T)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid uncertainty method\")\n",
    "            \n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "                  f'Val Accuracy: {val_accuracy:.4f}, Uncertainty Method: {uncertainty_method}')\n",
    "\n",
    "\n",
    "    def fit(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss, val_accuracy = self.test()\n",
    "                      \n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 4e-4\n",
    "num_epochs = 40\n",
    "\n",
    "\n",
    "\n",
    "# Model, loss function, optimizer\n",
    "model = VLR(dim=768).to(devices)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import FHM_dataload\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = FHM_dataload.load_train_FHM(batch_size)\n",
    "test_loader= FHM_dataload.load_test_FHM(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(model, train_loader, test_loader, criterion, optimizer, device=devices)\n",
    "trainer.fit(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zxf_001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
